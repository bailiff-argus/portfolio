{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81cc17cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "spam = pd.read_csv('./data/spam.csv')\n",
    "spam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfe3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "textcat = nlp.add_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf88163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label('ham')  # real messages\n",
    "textcat.add_label('spam') # spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0adce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = spam['text'].values\n",
    "\n",
    "train_labels = [\n",
    "    {'cats': {\n",
    "        'ham':  label == 'ham',\n",
    "        'spam': label == 'spam',\n",
    "        },\n",
    "    } for label in spam['label']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05ccb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  {'cats': {'ham': True, 'spam': False}}),\n",
       " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
       " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "  {'cats': {'ham': False, 'spam': True}}),\n",
       " ('U dun say so early hor... U c already then say...',\n",
       "  {'cats': {'ham': True, 'spam': False}}),\n",
       " (\"Nah I don't think he goes to usf, he lives around here though\",\n",
       "  {'cats': {'ham': True, 'spam': False}})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99385ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch\n",
    "\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "batches = minibatch(train_data, size = 8)\n",
    "\n",
    "num_elements_in_batches = 0\n",
    "for batch in batches:\n",
    "    num_elements_in_batches += 1\n",
    "    for text, labels in batch:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, labels)\n",
    "        nlp.update([example], sgd = optimizer)\n",
    "        \n",
    "print(num_elements_in_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e810276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 708.4780089379459}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "\n",
    "optimizer = nlp.initialize()\n",
    "losses = {}\n",
    "\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    batches = minibatch(train_data, size = 8)\n",
    "    \n",
    "    for batch in batches:\n",
    "        for text, labels in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            nlp.update([example], sgd = optimizer, losses = losses)\n",
    "            \n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f04185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999452e-01 5.4865004e-06]\n",
      " [1.6431263e-04 9.9983561e-01]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Are you ready for the tea party????? It\\'s gonna be wild!!!\",\n",
    "    \"URGENT Reply to this message for GUARANTEED FREE TEA\",\n",
    "]\n",
    "\n",
    "docs = [nlp.tokenizer(text) for text in texts]\n",
    "\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores = textcat.predict(docs)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "705f66af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'spam']\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = scores.argmax(axis = 1)\n",
    "print(\n",
    "    [textcat.labels[label] for label in predicted_labels]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee837c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a542e4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'll be the first to admit that I was not exci...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was really looking forward to visiting after...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Like walking back in time, every Saturday morn...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walked in around 4 on a Friday afternoon, we s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  sentiment\n",
       "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
       "2  I have to say that this office really has it t...    5.0          1\n",
       "3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
       "4  Today was my second out of three sessions I ha...    1.0          0\n",
       "5  I'll be the first to admit that I was not exci...    4.0          1\n",
       "6  This place has gone down hill.  Clearly they h...    1.0          0\n",
       "7  I was really looking forward to visiting after...    2.0          0\n",
       "8  Like walking back in time, every Saturday morn...    4.0          1\n",
       "9  Walked in around 4 on a Friday afternoon, we s...    1.0          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/yelp_ratings.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aedad1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file_path, split = 0.9):\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    train_data = data.sample(frac = 1, random_state = 1) # shuffle\n",
    "    \n",
    "    texts = train_data['text'].values\n",
    "    labels = [\n",
    "        {\n",
    "            'POSITIVE': bool(y),\n",
    "            'NEGATIVE': not bool(y),\n",
    "        } for y in train_data['sentiment'].values\n",
    "    ]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    train_labels = [{'cats': labels} for labels in labels[:split]]\n",
    "    valid_labels = [{'cats': labels} for labels in labels[split:]]\n",
    "    \n",
    "    return texts[:split], train_labels, texts[split:], valid_labels\n",
    "\n",
    "train_texts, train_labels, valid_texts, valid_labels = load_data('./data/yelp_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9049c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I ordered nachos, soft serve ice cream, and a salad. Probably the easiest '\n",
      "  \"things to prepare. It took a half hour and, if I hadn't looked in the bag-I \"\n",
      "  \"ordered everything to go-I wouldn't have realized that they forgot an item. \"\n",
      "  \"TERRIBLE service and they didn't care on bit. I will NEVER go back!\",\n",
      "  {'cats': {'NEGATIVE': True, 'POSITIVE': False}}),\n",
      " ('The restaurant with the food truck theme was very good. The overall '\n",
      "  'establishment was very clean and all the arcade games worked. The staff was '\n",
      "  'attentive and polite. It was a great experience. \\n'\n",
      "  '\\n'\n",
      "  'One particular instance stands out. We were going to the go carts and we '\n",
      "  'had one family with one adult and two kids. All three of them are going to '\n",
      "  \"sit it out because they didn't want to keep one kid out. However, one of \"\n",
      "  'the employees really stepped up and went with one of the kids. This was '\n",
      "  'unexpected and really above and beyond.\\n'\n",
      "  '\\n'\n",
      "  'We will be back.',\n",
      "  {'cats': {'NEGATIVE': False, 'POSITIVE': True}})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(list(\n",
    "    zip(train_texts[:2], train_labels[:2])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8ee491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "textcat.add_label('NEGATIVE')\n",
    "textcat.add_label('POSITIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d91d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, optimizer, batch_size = 8):\n",
    "    losses = {}\n",
    "    \n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    for batch in minibatch(train_data, size = batch_size):\n",
    "        for text, labels in batch:\n",
    "            doc = model.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            model.update([example], sgd = optimizer, losses = losses)\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0557a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.initialize()\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "losses = train(nlp, train_data, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bacb65fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'textcat': 6410.319330349245}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5edeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, texts):\n",
    "    docs = [model.tokenizer(text) for text in texts]\n",
    "    scores = textcat.predict(docs)\n",
    "    \n",
    "    predicted_class = scores.argmax(axis = 1)\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "575c6d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE: We eat here on a regular basis.  It's like that little hole in the wall place that has tasty food for reasonable prices here!  I can't vouch for their full menu... we always get the chicken in spicy garlic sauce... that's it.  They have lunch specials that come with a spring roll and fried or white rice... its delicious... love it.  White meat chicken and lots of veggies.  By hole in the wall I don't mean it in a bad way... these are the places that have the best food a lot of times.  Place always looks decently clean... if decently is even a word... but I love my dish... I would suggest it to anyone. \n",
      "\n",
      "POSITIVE: OMG! 1st off...let me say that I ate at Guy's restaurant in New York. It was ok. nothing special. But his restaurant in Las Vegas just blew me away! Humongous portions, compatable with their prices. The drinks were great. I had the mac and cheese burger (my favorite thing on earth!). Big, juicy patties with creamy mac and cheese), served with 4 kinds of fries (each with it's own spicyness, but not too spicy at all). For dessert I had the fried ice cream...oh, G-d! a gigantic ball of french vanilla ice cream fried in corn flakes with strawberry, pineapple and chocolate sauces on the plate, along with banana and peanut butter toppings, burbon sauce and whipped cream. All plated so that you can build your own bomb! All of the presentations were wonderful! Ate there again for lunch and had the pulled pork sandwich. Again...amazing! Guy,  you really outdid yourself! The only negative thing I could say is that if breakfast is going to stop serving early (which, according to the staff, the chef decides on that day), a sign should be posted outside to let people know. \n",
      "\n",
      "POSITIVE: AMAZING!!!! So so so so so good!! My mom, sister, and I stopped in before we saw a show and all loved our orders. I played it a little safe and got the spaghetti, my sister got the lasagna, and my mom got the burrata agnolotti. We all loved our meals and ate every single bite. The sauce for the spaghetti was so rich and flavorful and although I didn't try their selections my sister claimed it was the best lasagna she's ever tried. It is a little pricey but it's so worth it for the quality of the food and the great service. A must try if you're in Vegas! \n",
      "\n",
      "POSITIVE: Custom Tailor should be one word and a 4 letter word like \"LOVE\".\n",
      "It should not be abused.\n",
      "I took a dress here and the owner told me to take the dress somewhere else because he thought it fit fine.\n",
      "I am 5'7 105 lbs with no hips the top of the dress fit perfectly but the bottom was loose and it was supposed to be fitted pencil style (Helmut Lang)\n",
      "I am sure he is great with hems and taking up sleeves and taking in the waist of pants but \"custom tailor\" - not really..... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = valid_texts[34:38]\n",
    "predictions = predict(nlp, texts)\n",
    "\n",
    "for prediction, text in zip(predictions, texts):\n",
    "    print(\n",
    "        f\"{textcat.labels[prediction]}: {text} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3542e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, texts, labels):\n",
    "    predicted_class = predict(model, texts)\n",
    "    \n",
    "    true_class = [\n",
    "        int(label['cats']['POSITIVE'] == True) for label in labels\n",
    "    ]\n",
    "    \n",
    "    correct_predictions = [\n",
    "        predicted_class[i] == true_class[i] for i in range(len(predicted_class))\n",
    "    ]\n",
    "    \n",
    "    accuracy = sum(correct_predictions) / len(correct_predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e40422",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(nlp, valid_texts, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62f44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
